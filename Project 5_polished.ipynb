{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "please read this notebook in Nbviewer as it has an option of showing or hiding code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the project\n",
    "\n",
    "Enron case reprsented the largest bankruptcy reorganization in American history at that time, and also it led the the biggest audit failure, with the demise of then top five firm - Andersen.\n",
    "\n",
    "From a 90USD price per share, to a 1USD value represents the huge value loss and scam that happened in Enron. This case has been a point of interest for machine learning analysis because of the huge real-world impact that ML could help out and try to figure out what went wrong and how to avoid it in the future. It would be of great value to find a model that could potentially predict these types of events before much damage is done, so as to permit preventive action. Corporate governance, the stock market, and even the Government would be quite interested in a machine learning model that could signal potential fraud detections before hand.\n",
    "The goal of the project is to develop an algorithm that will identify Enron employee who lkeily committed fraud. The dataset consists of Enron email and financial data compiled into a dictionary.  Each key-value pair in the dictionary corresponds to one person. The dictionary key is the person's name, and the value is another dictionary, which contains the names of all the features and their values for that person. The features in the data fall into three major types, namely financial features, email features and POI labels. \n",
    "\n",
    "#### Use of ML\n",
    "Supervised machine learning algorithms can learn from a small dataset and process a large dataset to find trends and classify employees based on the training data. By identifying persons of interest using ML we could automate siginficant amount of work that would be done manually. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import math\n",
    "from tester import test_classifier, dump_classifier_and_data\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import math\n",
    "from tester import test_classifier, dump_classifier_and_data\n",
    "import numpy as np\n",
    "from numpy import log\n",
    "from numpy import sqrt\n",
    "from numpy import float64\n",
    "from numpy import nan\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from tester import dump_classifier_and_data\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Created data_dict list containing all pickled data for analysis\n",
    "import matplotlib\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi','salary'] # You will need to use more features\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "import pickle\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'email_address', 'from_poi_to_this_person']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Created data_dict list containing all pickled data for analysis\n",
    "features_all = []\n",
    "for v in data_dict['WHALEY DAVID A']:\n",
    "    features_all.append(v)\n",
    "oldindex = features_all.index('poi')\n",
    "features_all.insert(0, features_all.pop(oldindex))\n",
    "print features_all\n",
    "#print data_dict['SKILLING JEFFREY K']\n",
    "len(features_all)\n",
    ";    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "To identify outliers we need to transfer data to dataframe.\n",
    "We identified three clear outliers (TOTAL,  THE TRAVEL AGENCY, LOCKHART EUGENE E ). THE TRAVEL AGENCY and TOTAL are not real persons and should be taken out.  Mr. Lockhart does not have any data to his name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azizmamatov/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import pandas as pd\n",
    "def to_pandas(data_dict):\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    df = df.convert_objects(convert_numeric=True) #converted objects to Numbeic, like POI which was boolean\n",
    "    df = df.transpose() #original data_dict had all the info in rows instead of columns\n",
    "    df.reset_index(level=0, inplace=True) #resets the index column to just a column\n",
    "    columns = list(df.columns)\n",
    "    columns[0] = 'name' #index column is renamed to names\n",
    "    df.columns = columns\n",
    "    return(df)\n",
    "df = to_pandas(data_dict)\n",
    "df.to_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters of data\n",
    "* All emails adresses are NaN,\n",
    "* 146 people, and 21 features.\n",
    "* 128 non-POI and 18 POI\n",
    "* Following names have this percentage of NaN values: \n",
    "* LOCKHART EUGENE E\t\t95.238095\n",
    "* GRAMM WENDY L\t85.714286\n",
    "* SCRIMSHAW MATTHEW\t85.714286\n",
    "* THE TRAVEL AGENCY IN THE PARK\t85.714286\n",
    "* WHALEY DAVID A\t85.714286\n",
    "* WODRASKA JOHN\t85.714286\n",
    "* WROBEL BRUCE\t85.714286\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.200000e+01</td>\n",
       "      <td>3.900000e+01</td>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.020000e+02</td>\n",
       "      <td>9.500000e+01</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.600000e+01</td>\n",
       "      <td>9.300000e+01</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>1.100000e+02</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>9.500000e+01</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.250000e+02</td>\n",
       "      <td>1.260000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.374235e+06</td>\n",
       "      <td>1.642674e+06</td>\n",
       "      <td>-1.140475e+06</td>\n",
       "      <td>1.668049e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.987054e+06</td>\n",
       "      <td>1.087289e+05</td>\n",
       "      <td>608.790698</td>\n",
       "      <td>64.895349</td>\n",
       "      <td>41.232558</td>\n",
       "      <td>...</td>\n",
       "      <td>1.470361e+06</td>\n",
       "      <td>9.190650e+05</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>2.321741e+06</td>\n",
       "      <td>1.664106e+05</td>\n",
       "      <td>5.621943e+05</td>\n",
       "      <td>1176.465116</td>\n",
       "      <td>2073.860465</td>\n",
       "      <td>5.081526e+06</td>\n",
       "      <td>6.773957e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.071333e+07</td>\n",
       "      <td>5.161930e+06</td>\n",
       "      <td>4.025406e+06</td>\n",
       "      <td>3.198914e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.106201e+07</td>\n",
       "      <td>5.335348e+05</td>\n",
       "      <td>1841.033949</td>\n",
       "      <td>86.979244</td>\n",
       "      <td>100.073111</td>\n",
       "      <td>...</td>\n",
       "      <td>5.942759e+06</td>\n",
       "      <td>4.589253e+06</td>\n",
       "      <td>0.329899</td>\n",
       "      <td>1.251828e+07</td>\n",
       "      <td>4.201494e+06</td>\n",
       "      <td>2.716369e+06</td>\n",
       "      <td>1178.317641</td>\n",
       "      <td>2582.700981</td>\n",
       "      <td>2.906172e+07</td>\n",
       "      <td>3.895777e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>-1.025000e+05</td>\n",
       "      <td>-2.799289e+07</td>\n",
       "      <td>3.285000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.285000e+03</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.922300e+04</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.604490e+06</td>\n",
       "      <td>-7.576788e+06</td>\n",
       "      <td>4.770000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>-4.409300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.734362e+07</td>\n",
       "      <td>3.208340e+07</td>\n",
       "      <td>-8.330000e+02</td>\n",
       "      <td>1.398517e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.117640e+08</td>\n",
       "      <td>5.235198e+06</td>\n",
       "      <td>14368.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.852193e+07</td>\n",
       "      <td>4.266759e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.303223e+08</td>\n",
       "      <td>1.545629e+07</td>\n",
       "      <td>2.670423e+07</td>\n",
       "      <td>5521.000000</td>\n",
       "      <td>15149.000000</td>\n",
       "      <td>3.098866e+08</td>\n",
       "      <td>4.345095e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              bonus  deferral_payments  deferred_income  director_fees  \\\n",
       "count  8.200000e+01       3.900000e+01     4.900000e+01   1.700000e+01   \n",
       "mean   2.374235e+06       1.642674e+06    -1.140475e+06   1.668049e+05   \n",
       "std    1.071333e+07       5.161930e+06     4.025406e+06   3.198914e+05   \n",
       "min    7.000000e+04      -1.025000e+05    -2.799289e+07   3.285000e+03   \n",
       "25%             NaN                NaN              NaN            NaN   \n",
       "50%             NaN                NaN              NaN            NaN   \n",
       "75%             NaN                NaN              NaN            NaN   \n",
       "max    9.734362e+07       3.208340e+07    -8.330000e+02   1.398517e+06   \n",
       "\n",
       "       email_address  exercised_stock_options      expenses  from_messages  \\\n",
       "count            0.0             1.020000e+02  9.500000e+01      86.000000   \n",
       "mean             NaN             5.987054e+06  1.087289e+05     608.790698   \n",
       "std              NaN             3.106201e+07  5.335348e+05    1841.033949   \n",
       "min              NaN             3.285000e+03  1.480000e+02      12.000000   \n",
       "25%              NaN                      NaN           NaN            NaN   \n",
       "50%              NaN                      NaN           NaN            NaN   \n",
       "75%              NaN                      NaN           NaN            NaN   \n",
       "max              NaN             3.117640e+08  5.235198e+06   14368.000000   \n",
       "\n",
       "       from_poi_to_this_person  from_this_person_to_poi        ...          \\\n",
       "count                86.000000                86.000000        ...           \n",
       "mean                 64.895349                41.232558        ...           \n",
       "std                  86.979244               100.073111        ...           \n",
       "min                   0.000000                 0.000000        ...           \n",
       "25%                        NaN                      NaN        ...           \n",
       "50%                        NaN                      NaN        ...           \n",
       "75%                        NaN                      NaN        ...           \n",
       "max                 528.000000               609.000000        ...           \n",
       "\n",
       "       long_term_incentive         other         poi  restricted_stock  \\\n",
       "count         6.600000e+01  9.300000e+01  146.000000      1.100000e+02   \n",
       "mean          1.470361e+06  9.190650e+05    0.123288      2.321741e+06   \n",
       "std           5.942759e+06  4.589253e+06    0.329899      1.251828e+07   \n",
       "min           6.922300e+04  2.000000e+00    0.000000     -2.604490e+06   \n",
       "25%                    NaN           NaN    0.000000               NaN   \n",
       "50%                    NaN           NaN    0.000000               NaN   \n",
       "75%                    NaN           NaN    0.000000               NaN   \n",
       "max           4.852193e+07  4.266759e+07    1.000000      1.303223e+08   \n",
       "\n",
       "       restricted_stock_deferred        salary  shared_receipt_with_poi  \\\n",
       "count               1.800000e+01  9.500000e+01                86.000000   \n",
       "mean                1.664106e+05  5.621943e+05              1176.465116   \n",
       "std                 4.201494e+06  2.716369e+06              1178.317641   \n",
       "min                -7.576788e+06  4.770000e+02                 2.000000   \n",
       "25%                          NaN           NaN                      NaN   \n",
       "50%                          NaN           NaN                      NaN   \n",
       "75%                          NaN           NaN                      NaN   \n",
       "max                 1.545629e+07  2.670423e+07              5521.000000   \n",
       "\n",
       "        to_messages  total_payments  total_stock_value  \n",
       "count     86.000000    1.250000e+02       1.260000e+02  \n",
       "mean    2073.860465    5.081526e+06       6.773957e+06  \n",
       "std     2582.700981    2.906172e+07       3.895777e+07  \n",
       "min       57.000000    1.480000e+02      -4.409300e+04  \n",
       "25%             NaN             NaN                NaN  \n",
       "50%             NaN             NaN                NaN  \n",
       "75%             NaN             NaN                NaN  \n",
       "max    15149.000000    3.098866e+08       4.345095e+08  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%capture\n",
    "df.shape\n",
    "print df.groupby(['poi']).size() # we can see number of poi\n",
    "df.describe();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Total' outlier.\n",
    "Total is just a sum of values and should be taken out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>97343619.0</td>\n",
       "      <td>32083396.0</td>\n",
       "      <td>-27992891.0</td>\n",
       "      <td>1398517.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>311764000.0</td>\n",
       "      <td>5235198.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>48521928.0</td>\n",
       "      <td>42667589.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130322299.0</td>\n",
       "      <td>-7576788.0</td>\n",
       "      <td>26704229.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309886585.0</td>\n",
       "      <td>434509511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>SKILLING JEFFREY K</td>\n",
       "      <td>5600000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19250000.0</td>\n",
       "      <td>29336.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1920000.0</td>\n",
       "      <td>22122.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6843672.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1111258.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>3627.0</td>\n",
       "      <td>8682716.0</td>\n",
       "      <td>26093672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>LAY KENNETH L</td>\n",
       "      <td>7000000.0</td>\n",
       "      <td>202911.0</td>\n",
       "      <td>-300000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34348384.0</td>\n",
       "      <td>99832.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>10359729.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14761694.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1072321.0</td>\n",
       "      <td>2411.0</td>\n",
       "      <td>4273.0</td>\n",
       "      <td>103559793.0</td>\n",
       "      <td>49110078.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>FREVERT MARK A</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>6426990.0</td>\n",
       "      <td>-3367011.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10433518.0</td>\n",
       "      <td>86987.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1617011.0</td>\n",
       "      <td>7427621.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4188667.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1060932.0</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>17252530.0</td>\n",
       "      <td>14622185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>PICKERING MARK R</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28798.0</td>\n",
       "      <td>31653.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>655037.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>1386690.0</td>\n",
       "      <td>28798.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name       bonus  deferral_payments  deferred_income  \\\n",
       "130               TOTAL  97343619.0         32083396.0      -27992891.0   \n",
       "122  SKILLING JEFFREY K   5600000.0                NaN              NaN   \n",
       "79        LAY KENNETH L   7000000.0           202911.0        -300000.0   \n",
       "47       FREVERT MARK A   2000000.0          6426990.0       -3367011.0   \n",
       "105    PICKERING MARK R    300000.0                NaN              NaN   \n",
       "\n",
       "     director_fees  email_address  exercised_stock_options   expenses  \\\n",
       "130      1398517.0            NaN              311764000.0  5235198.0   \n",
       "122            NaN            NaN               19250000.0    29336.0   \n",
       "79             NaN            NaN               34348384.0    99832.0   \n",
       "47             NaN            NaN               10433518.0    86987.0   \n",
       "105            NaN            NaN                  28798.0    31653.0   \n",
       "\n",
       "     from_messages  from_poi_to_this_person        ...          \\\n",
       "130            NaN                      NaN        ...           \n",
       "122          108.0                     88.0        ...           \n",
       "79            36.0                    123.0        ...           \n",
       "47            21.0                    242.0        ...           \n",
       "105           67.0                      7.0        ...           \n",
       "\n",
       "     long_term_incentive       other  poi  restricted_stock  \\\n",
       "130           48521928.0  42667589.0  0.0       130322299.0   \n",
       "122            1920000.0     22122.0  1.0         6843672.0   \n",
       "79             3600000.0  10359729.0  1.0        14761694.0   \n",
       "47             1617011.0   7427621.0  0.0         4188667.0   \n",
       "105                  NaN         NaN  0.0               NaN   \n",
       "\n",
       "     restricted_stock_deferred      salary  shared_receipt_with_poi  \\\n",
       "130                 -7576788.0  26704229.0                      NaN   \n",
       "122                        NaN   1111258.0                   2042.0   \n",
       "79                         NaN   1072321.0                   2411.0   \n",
       "47                         NaN   1060932.0                   2979.0   \n",
       "105                        NaN    655037.0                    728.0   \n",
       "\n",
       "     to_messages  total_payments  total_stock_value  \n",
       "130          NaN     309886585.0        434509511.0  \n",
       "122       3627.0       8682716.0         26093672.0  \n",
       "79        4273.0     103559793.0         49110078.0  \n",
       "47        3275.0      17252530.0         14622185.0  \n",
       "105        898.0       1386690.0            28798.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name'].groupby(df['salary']).max()\n",
    "df.sort_values(by=['salary','name'], ascending=[False, False]).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azizmamatov/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    }
   ],
   "source": [
    "#### New dataframe with columns by names to determine NaN and similar data for our labels\n",
    "df['name'].isnull().sum()\n",
    "df_names = pd.DataFrame(data_dict)\n",
    "df_names = df_names.convert_objects(convert_numeric=True)\n",
    "#df_names.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula to determine NaN values for names\n",
    "Nice summary, where first seven names have too many Nan values (more than 85%). LOCKHART EUGENE E does not have any values - all 20 columns are empty for him and he should be taken out of the list.\n",
    "I took the below code from : https://stackoverflow.com/questions/26266362/how-to-count-the-nan-values-in-the-column-in-panda-data-frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOCKHART EUGENE E</th>\n",
       "      <td>20</td>\n",
       "      <td>95.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRAMM WENDY L</th>\n",
       "      <td>18</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCRIMSHAW MATTHEW</th>\n",
       "      <td>18</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THE TRAVEL AGENCY IN THE PARK</th>\n",
       "      <td>18</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHALEY DAVID A</th>\n",
       "      <td>18</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WODRASKA JOHN</th>\n",
       "      <td>18</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WROBEL BRUCE</th>\n",
       "      <td>18</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHRISTODOULOU DIOMEDES</th>\n",
       "      <td>17</td>\n",
       "      <td>80.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLINE KENNETH W</th>\n",
       "      <td>17</td>\n",
       "      <td>80.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GILLIS JOHN</th>\n",
       "      <td>17</td>\n",
       "      <td>80.952381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Missing Values  % of Total Values\n",
       "LOCKHART EUGENE E                          20          95.238095\n",
       "GRAMM WENDY L                              18          85.714286\n",
       "SCRIMSHAW MATTHEW                          18          85.714286\n",
       "THE TRAVEL AGENCY IN THE PARK              18          85.714286\n",
       "WHALEY DAVID A                             18          85.714286\n",
       "WODRASKA JOHN                              18          85.714286\n",
       "WROBEL BRUCE                               18          85.714286\n",
       "CHRISTODOULOU DIOMEDES                     17          80.952381\n",
       "CLINE KENNETH W                            17          80.952381\n",
       "GILLIS JOHN                                17          80.952381"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names.isnull().sum()\n",
    "def missing_values_table(df): \n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum()/len(df)\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        return mis_val_table_ren_columns \n",
    "names_dataframe = missing_values_table(df_names) \n",
    "#sorting the names descending and showing first 10 names only\n",
    "names_dataframe.sort_values(by=['Missing Values','% of Total Values'], ascending=[False, False]).head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### New dataframe with columns by names to determine NaN and similar data for our labels\n",
    "### Deleted outliers from data_dict\n",
    "del data_dict['TOTAL']\n",
    "del data_dict['THE TRAVEL AGENCY IN THE PARK']\n",
    "del data_dict['LOCKHART EUGENE E']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  New features\n",
    "* 'Total stock value' = 'exercised_stock_options' + 'restricted_stock' + 'restricted_stock_deferred'\n",
    " \n",
    "* 'Total payments'= 'salary' + 'deferral_payments' + 'bonus'+ 'expenses' + 'loan_advances'+ 'director_fees' 'deferred_income' + 'long_term_incentive'\n",
    "Will divide features by financials, non-financial and label.\n",
    "\n",
    "#### Log features\n",
    "I added some new features, based on log of financial data, to make sure that the data is not widely dispersed as it is. Aslo I created features for ratio of emails to and from POI persons to total emails. This helped to establish relative numbers instead of absolute ones.\n",
    "\n",
    "#### Non-financial features should be added with ratio based ones, like percentage of poi related message to total messages.\n",
    "* 'poi_ratio_from' = 'from_this_person_to_poi' / 'from_messages'\n",
    "* 'poi_ratio_to' = 'from_poi_to_this_person' / 'to_messages'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8098092096 0.0470879801735 13.8755015673\n"
     ]
    }
   ],
   "source": [
    "#divide features by labels and financial and non-financial\n",
    "import pickle\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict_log = pickle.load(data_file)\n",
    "\n",
    "financial_features = ['salary', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', \n",
    "                      'restricted_stock', 'restricted_stock_deferred', 'total_stock_value', 'expenses',\n",
    "                      'loan_advances','other', 'director_fees', 'deferred_income', 'long_term_incentive']\n",
    "non_financials_features = ['to_messages', 'shared_receipt_with_poi', 'from_messages', \n",
    "                           'from_this_person_to_poi', 'from_poi_to_this_person']\n",
    "poi_label = ['poi']\n",
    "features_new = [\"poi_ratio_from\", 'poi_ratio_to',\"total_payments_log\", \"salary_log\",\"bonus_log\",\n",
    "                \"total_stock_value_log\", \"exercised_stock_options_log\"]\n",
    "\n",
    "NANvalue = 'NaN'\n",
    "for key in data_dict_log:\n",
    "#creating new financial features            \n",
    "    for feat in financial_features:\n",
    "        try:\n",
    "            data_dict_log[key][feat + '_log'] = math.log(data_dict_log[key][feat])\n",
    "        except:\n",
    "            data_dict_log[key][feat + '_log'] = NANvalue   \n",
    "            \n",
    "#creating new non_financial features   \n",
    "    try: \n",
    "        data_dict_log[key]['poi_ratio_from'] = \\\n",
    "        1. * data_dict_log[key]['from_this_person_to_poi'] / data_dict_log[key]['from_messages']\n",
    "        data_dict_log[key]['poi_ratio_to'] = \\\n",
    "        1. * data_dict_log[key]['from_poi_to_this_person'] / data_dict_log[key]['to_messages'] * 1.\n",
    "    except:\n",
    "        data_dict_log[key]['poi_ratio_from'] = NANvalue\n",
    "        data_dict_log[key]['poi_ratio_to'] = NANvalue\n",
    "            \n",
    "            \n",
    "for k, v in data_dict_log.iteritems():\n",
    "    print data_dict_log[k]['salary_log'], \\\n",
    "data_dict_log[k]['poi_ratio_to'], data_dict_log[k]['total_payments_log'] \n",
    "    break\n",
    "\n",
    "features_list = poi_label + financial_features + non_financials_features + features_new;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Creating featureFormat dataset\n",
    "my_dataset = data_dict_log\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True) \n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling features\n",
    "We may scale all the features via min-max algorithm. Some of the algorithms like logistics regression perform the best with scaled features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def scale_features(features):\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "#    return features\n",
    "#scale_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Splitting data into training and test\n",
    "from sklearn import cross_validation\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try a varity of classifiers\n",
    "There are various algorithms that we studies including the list below, and I decided to use GuassianNB, Decision tree classifier,  Logistic Regression and Gradient Boosting.\n",
    "\n",
    "#### Need to select at least two algorithms, compare their performance and tune the parameters for two algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree classifier\n",
    "We have some manual tuning to determine which parameters to add to each algorithm and adding/removing features. \n",
    "\n",
    "Parameter tuning is important because it optimizes an algorithm's performance on the data set. To measure the algorithm's performance, the data shoulld be validated and evaluated for different combinations of selected parameters. Algorithms are usually general in nature and are not  tuned to particular data set. Therefore, we should iteratively tune the algorithm until a satisfactory outcome is obtained.\n",
    "##### As we can see below the maximum results are under 'min_samples_split' parameter of 2. However, none of the scores are acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before tuning, decision tree = 0.727272727273\n",
      "precision before tuning, decision tree =  0.125\n",
      "recall = before tuning, decision tree =  0.166666666667\n",
      "Accuracy after tuning, [0.72727272727272729, 0.125, 0.16666666666666666, 0.70454545454545459, 0.1111111111111111, 0.16666666666666666, 0.72727272727272729, 0.125, 0.16666666666666666, 0.86363636363636365, 0.0, 0.0, 0.86363636363636365, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Please name your classifier clf for easy export below.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train,labels_train)\n",
    "#score = clf.score(features_test,labels_test)\n",
    "pred= clf.predict(features_test)\n",
    "acc=accuracy_score(labels_test, pred)\n",
    "print 'Accuracy before tuning, decision tree =', acc\n",
    "print 'precision before tuning, decision tree = ', precision_score(labels_test,pred)\n",
    "print 'recall = before tuning, decision tree = ', recall_score(labels_test,pred)\n",
    "\n",
    "split = [2,3,5,100,10000]\n",
    "new_scores = []\n",
    "for i in split:\n",
    "    clf = DecisionTreeClassifier(min_samples_split=i)\n",
    "    clf = clf.fit(features_train,labels_train)\n",
    "    pred= clf.predict(features_test)\n",
    "    acc=accuracy_score(labels_test, pred)\n",
    "    new_scores.append(acc)\n",
    "    precision = precision_score(labels_test,pred)\n",
    "    new_scores.append(precision)\n",
    "    recall = recall_score(labels_test,pred)\n",
    "    new_scores.append(recall)\n",
    "\n",
    "print 'Accuracy after tuning,', new_scores    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression\n",
    "Maximum scores are under 'C' parameter value of 10 and 10000 in our list. However, they are not sufficient for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before tuning, logistic regression = 0.772727272727\n",
      "recall before tuning, logistic regression =  0.166666666667\n",
      "precision before tuning, logistic regression =  0.166666666667\n",
      "Accuracy after tuning, [0.79545454545454541, 0.20000000000000001, 0.16666666666666666, 0.72727272727272729, 0.20000000000000001, 0.33333333333333331, 0.77272727272727271, 0.16666666666666666, 0.16666666666666666, 0.79545454545454541, 0.2857142857142857, 0.33333333333333331]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "acc=accuracy_score(labels_test, pred)\n",
    "print 'Accuracy before tuning, logistic regression =', acc #clf.score(features_train, labels_train)\n",
    "print 'recall before tuning, logistic regression = ', recall_score(labels_test, pred)\n",
    "print 'precision before tuning, logistic regression = ', precision_score(labels_test, pred)\n",
    "\n",
    "C = [5,10,100,10000]\n",
    "new_scores = []\n",
    "for i in C:\n",
    "    clf = LogisticRegression(C=i)\n",
    "    clf = clf.fit(features_train,labels_train)\n",
    "    pred= clf.predict(features_test)\n",
    "    acc=accuracy_score(labels_test, pred)\n",
    "    new_scores.append(acc)\n",
    "    precision = precision_score(labels_test,pred)\n",
    "    new_scores.append(precision)\n",
    "    recall = recall_score(labels_test,pred)\n",
    "    new_scores.append(recall)\n",
    "\n",
    "print 'Accuracy after tuning,', new_scores    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Gradient Boosting\n",
    "I used all the features in Gradient Boosting which is one of the ensemble methods and actually uses all the available features. Gradient boosting is using boosting methods where base estimators are built sequentially and one tries to reduce the bias of the combined estimator. The motivation is to combine several weak models to produce a powerful ensemble. As such, all of the available features are used, unless there are too many of them. \n",
    "\n",
    "Maximum scores are under 'max_depth' parameter value of 2 in our list and they stay the same once they increase. They provide acceptable scores under this environment, however it is not enough for tester.py file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before tuning, GradientBoosting  = 0.863636363636\n",
      "recall before tuning,  = GradientBoosting 0.166666666667\n",
      "precision before tuning, = GradientBoosting 0.5\n",
      "Accuracy after tuning, [0.88636363636363635, 0.66666666666666663, 0.33333333333333331, 0.81818181818181823, 0.25, 0.16666666666666666, 0.72727272727272729, 0.125, 0.16666666666666666, 0.72727272727272729, 0.125, 0.16666666666666666, 0.72727272727272729, 0.125, 0.16666666666666666]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "acc=accuracy_score(labels_test, pred)\n",
    "print 'Accuracy before tuning, GradientBoosting  =', acc #clf.score(features_train, labels_train)\n",
    "print 'recall before tuning,  = GradientBoosting', recall_score(labels_test, pred)\n",
    "print 'precision before tuning, = GradientBoosting', precision_score(labels_test, pred)\n",
    "\n",
    "maxdepth = [2, 5,10,100,10000]\n",
    "new_scores = []\n",
    "for i in maxdepth:\n",
    "    clf = GradientBoostingClassifier(max_depth=i)\n",
    "    clf = clf.fit(features_train,labels_train)\n",
    "    pred= clf.predict(features_test)\n",
    "    acc=accuracy_score(labels_test, pred)\n",
    "    new_scores.append(acc)\n",
    "    precision = precision_score(labels_test,pred)\n",
    "    new_scores.append(precision)\n",
    "    recall = recall_score(labels_test,pred)\n",
    "    new_scores.append(recall)\n",
    "print 'Accuracy after tuning,', new_scores    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB\n",
    "This algorithm does not have any parameters to be adjusted however it needs to have good feature selection to work properly. As of now it does not provide acceptable results. I will need to explore feature selection and also experiment with scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB precision score 0.162162162162 recall score 1.0 accuracy 0.295454545455\n"
     ]
    }
   ],
   "source": [
    "#GaussianNB, it has no parameters to adjust, so I will try selectKbest later\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train,labels_train)\n",
    "pred= clf.predict(features_test)\n",
    "acc=accuracy_score(labels_test, pred)\n",
    "precision = precision_score(labels_test,pred)\n",
    "recall = recall_score(labels_test,pred)\n",
    "print \"GaussianNB precision score\", precision, 'recall score', recall, 'accuracy', acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "The above results from GaussianNB came from using all our features and it clearly does not work. The linear algorithms like GaussianNB need to have an optimal number of features. Ensemble algorithm deals with this problem but it did not work in our case, as the tester.py file run showed suboptimal results.\n",
    "Using too many features can also result in overfitting for linear algorithms. We will try the best features selection for GaussianNB algorithm.\n",
    "Best five feature below return a very good score so we can focus on feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall  1.0\n",
      "precision 0.375\n",
      "BestK score:  0.772727272727\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# let's see what we can do with the best five features (k=5)\n",
    "best_features = SelectKBest(k=5).fit(features_train, labels_train)\n",
    "\n",
    "features_train_1 = best_features.transform(features_train)\n",
    "features_test_1 = best_features.transform(features_test)\n",
    "\n",
    "clf.fit(features_train_1,labels_train)\n",
    "pred = clf.predict(features_test_1)\n",
    "score = accuracy_score(labels_test, pred)\n",
    "print 'recall ', recall_score(labels_test, pred)\n",
    "print 'precision', precision_score(labels_test, pred)\n",
    "\n",
    "print \"BestK score: \", score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importances with forests of trees¶\n",
    "We will build a graph to see which features are important for Gaussian NB and as we can see, majority of features are importants but first six features are especially important.  Features have decreasing importance over each feature. The most important features are payment related ones.\n",
    "http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Feature ranking:\n",
      "1. feature salary (0.077746)\n",
      "2. feature deferral_payments (0.075341)\n",
      "3. feature total_payments (0.070364)\n",
      "4. feature exercised_stock_options (0.064510)\n",
      "5. feature bonus (0.062549)\n",
      "6. feature restricted_stock (0.061644)\n",
      "7. feature restricted_stock_deferred (0.054767)\n",
      "8. feature total_stock_value (0.050924)\n",
      "9. feature expenses (0.048972)\n",
      "10. feature loan_advances (0.041997)\n",
      "11. feature other (0.041933)\n",
      "12. feature director_fees (0.041326)\n",
      "13. feature deferred_income (0.040427)\n",
      "14. feature long_term_incentive (0.040056)\n",
      "15. feature to_messages (0.039222)\n",
      "16. feature shared_receipt_with_poi (0.033064)\n",
      "17. feature from_messages (0.031094)\n",
      "18. feature from_this_person_to_poi (0.026213)\n",
      "19. feature from_poi_to_this_person (0.021388)\n",
      "20. feature poi_ratio_from (0.019322)\n",
      "21. feature poi_ratio_to (0.017167)\n",
      "22. feature total_payments_log (0.017072)\n",
      "23. feature salary_log (0.008952)\n",
      "24. feature bonus_log (0.008087)\n",
      "25. feature total_stock_value_log (0.004160)\n",
      "26. feature exercised_stock_options_log (0.001702)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAFyCAYAAABC/SgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwszMzHLhpMLMzMxy8f8BTXl3qRIcH04AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11028e510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)  # your feature and labels\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "\n",
    "# Build a classification task using 3 informative features\n",
    "X, y = features_train, labels_train\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(len(features_list)-1):\n",
    "    print(\"%d. feature %s (%f)\" % (f+1, features_list[1:][f], importances[indices[f]]))\n",
    "# Plot the feature importances of the forest\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(features_list)-1), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(len(features_list)-1), indices)\n",
    "plt.xlim([-1, (len(features_list)-1)])\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gridsearch on Gradient boosting \n",
    "N-estimators = 10, Max_depth = 1, All features are used\n",
    "Returns acceptable results on our training data set but not on tester.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=1,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "0.862068965517\n",
      "[mean: 0.87931, std: 0.03421, params: {'n_estimators': 10, 'max_depth': 1}, mean: 0.83621, std: 0.06740, params: {'n_estimators': 100, 'max_depth': 1}, mean: 0.79310, std: 0.05349, params: {'n_estimators': 1000, 'max_depth': 1}, mean: 0.85345, std: 0.04773, params: {'n_estimators': 10, 'max_depth': 2}, mean: 0.81034, std: 0.06369, params: {'n_estimators': 100, 'max_depth': 2}, mean: 0.78448, std: 0.08050, params: {'n_estimators': 1000, 'max_depth': 2}, mean: 0.81897, std: 0.04036, params: {'n_estimators': 10, 'max_depth': 5}, mean: 0.81897, std: 0.05729, params: {'n_estimators': 100, 'max_depth': 5}, mean: 0.81897, std: 0.05729, params: {'n_estimators': 1000, 'max_depth': 5}]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# applying GridSearch on GradientBoostingClassifier only\n",
    "\n",
    "param_grid = {'n_estimators': [10, 100, 1000],'max_depth': [1, 2, 5]}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), cv=10, n_jobs=-1, param_grid=param_grid)\n",
    "grid_search.fit(features_train, labels_train)\n",
    "clf = grid_search.best_estimator_\n",
    "\n",
    "print clf\n",
    "print grid_search.best_estimator_.score(features_test, labels_test)\n",
    "print grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gridseach with PCA on GradientBoosting\n",
    "Returns acceptable results on our training data set but not acceptable results on tester.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('reduce_dim', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=5,\n",
      "              max_featur...=100, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False))])\n",
      "0.862068965517\n",
      "[mean: 0.85345, std: 0.06526, params: {'clf__max_depth': 5, 'reduce_dim__n_components': 2}, mean: 0.85345, std: 0.07689, params: {'clf__max_depth': 5, 'reduce_dim__n_components': 3}, mean: 0.85345, std: 0.06526, params: {'clf__max_depth': 6, 'reduce_dim__n_components': 2}, mean: 0.85345, std: 0.09227, params: {'clf__max_depth': 6, 'reduce_dim__n_components': 3}]\n"
     ]
    }
   ],
   "source": [
    "# applying grid search on GradientBoostingClassifier but with pipeline which inludes PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "estimators = [('reduce_dim', PCA()), ('clf', GradientBoostingClassifier())]\n",
    "pipe = Pipeline(estimators)\n",
    " \n",
    "\n",
    "#param_grid = dict(selectkbest__k = range(20,25))\n",
    "\n",
    "param_grid = {'reduce_dim__n_components': [2, 3],\n",
    "               'clf__max_depth': [5,6]\n",
    "          }\n",
    "\n",
    "grid_search = GridSearchCV(pipe, cv=10, n_jobs=-1, param_grid = param_grid)\n",
    "grid_search.fit(features_train, labels_train)\n",
    "clf = grid_search.best_estimator_\n",
    "\n",
    "print clf\n",
    "print grid_search.best_estimator_.score(features_test, labels_test)\n",
    "print grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch CV on Gaussian NB - great results\n",
    "As we discussed above, Gradient Boosting did not return acceptable results in tester.py and GaussianNB showed promising results when we experimented with feature selection. So we are going to apply GridSearchCV on GaussianNB.\n",
    "I applied minimum 5 features as it showed good results in feature selections. I also tried applying PCA but it didn't return great results with this algorithm. When I took out the PCA, and showed acceptable results.\n",
    "\n",
    "I selected Gaussian NB algorithm because it showed great results on selected features and without even applying PCA. Initially, I thought that the GradientBoosting will work however it did not on tester.py data, probably because of cross validations issues and the fact that there were too many features to be used.\n",
    "\n",
    "Final top five features selected were as below:\n",
    "\n",
    "1. salary \n",
    "2. deferral_payments\n",
    "3. total_payments \n",
    "4. exercised_stock_options \n",
    "5. bonus \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm results\n",
    "\n",
    "| Algorithm | Accuracy | Precision | Recall | F1 | F2 | Total predictions | True positives | False positives | False negatives | True negatives\n",
    "|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|GaussianNB()|0.84673|0.40743|0.32900|0.36404|0.34217|15000|658|957|1342|12043|\n",
    "|GradientBoostingClassifier()| 0.88000|0.93478|0.10750|0.19283|0.13062|15000|215|15|1785|12985|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('selectkbest', SelectKBest(k=8, score_func=<function f_classif at 0x10bec7938>)), ('naive_bayes', GaussianNB(priors=None))])\n",
      "0.75\n",
      "{'selectkbest__k': 8}\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "GNB = GaussianNB()\n",
    "DTC = DecisionTreeClassifier()\n",
    "LR = LogisticRegression()\n",
    "\n",
    "param_grid = {'selectkbest__k': range(5,27)}\n",
    "\n",
    "# Create the pipline to use in Task 5\n",
    "pipeline = Pipeline([#('reduce_dim', PCA()),\n",
    "                     ('selectkbest', SelectKBest()),\n",
    "                    ('naive_bayes', GNB), #('min_max_scaler', scaler)\n",
    "                    ])\n",
    "#('min_max_scaler', scaler)]\n",
    "grid_search = GridSearchCV(pipeline, cv=10, n_jobs=-1, param_grid = param_grid)\n",
    "grid_search.fit(features_train, labels_train)\n",
    "clf = grid_search.best_estimator_\n",
    "pred = clf.predict(features_test)\n",
    "#acc=accuracy_score(labels_test, pred)\n",
    "#precision = precision_score(labels_test,pred)\n",
    "#recall = recall_score(labels_test,pred)\n",
    "\n",
    "print clf\n",
    "print grid_search.best_estimator_.score(features_test, labels_test)\n",
    "print grid_search.best_params_,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Tuning:\n",
    "Parameters of algorithm play a decisive role in the quality of the prediction. If the parameters are not tuned well then the resulting accuracy score, recall and precision scores would be either not acceptable or below the desired standard. Algorithms are usually very general in natures and as such should be tuned. \n",
    "However, no parameter tuning was required for GaussianNB except for careful feature selection.\n",
    "For other algorithms I used you can see parameter tuning above where I was experimenting with specific parameters for each algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation\n",
    "Validation allows to find a suitable result between bias and variance. High variance will result in overfitting the data while high bias will result in underfiting the data. As such, the data should be carefully split into training and testing sets. \n",
    "The train_test_split method was used to split the provided dataset (30% test, - 70% train), and then the GridSearchCV.\n",
    "\n",
    "#### Evaluation\n",
    "Give at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance. [relevant rubric item: “usage of evaluation metrics”]\n",
    "\n",
    "I used three evaluation metrics - recall, precision and accuracy. After tuning they equalled: \n",
    "* Accuracy = 0.86, \n",
    "* recall = 0.33, \n",
    "* precision 0.41.\n",
    "\n",
    "Accuracy is not the best evaluation metric because of the sparcity of the label - POI. That is why precision and evaluation is used. Precision is the ratio of the model being correct for positive label to the total times of guess as positive labels. A higher precision score means less false positives.\n",
    "Recall ks the ratio of model being correct for positive labels as to total number of positive labels. A higher recall score means less false negatives.\n",
    "Recall is the most important criteria as we would need to find all people who were involved and then we would gradually clear them if they are innocent during the investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "* http://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting\n",
    "* http://scikit-learn.org/stable/modules/pipeline.html\n",
    "* http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "* https://stackoverflow.com/questions/26266362/how-to-count-the-nan-values-in-the-column-in-panda-data-frame\n",
    "* http://chris-said.io/2016/02/13/how-to-make-polished-jupyter-presentations-with-optional-code-visibility/\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#999; background:#fff;\">\n",
    "Created with Jupyter, delivered by Fastly, rendered by Rackspace.\n",
    "</footer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
