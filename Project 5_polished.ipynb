{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import math\n",
    "from tester import test_classifier, dump_classifier_and_data\n",
    "\n",
    "import numpy as np\n",
    "from numpy import log\n",
    "from numpy import sqrt\n",
    "from numpy import float64\n",
    "from numpy import nan\n",
    "\n",
    "from time import time\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib\n",
    "import sys\n",
    "import pickle\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created data_dict list containing all pickled data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi','salary'] # You will need to use more features\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "import pickle\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Created a list of all features 'features_all' from data_dict list and moved 'poi' to first position requred for function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'salary', 'to_messages', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', 'restricted_stock', 'shared_receipt_with_poi', 'restricted_stock_deferred', 'total_stock_value', 'expenses', 'loan_advances', 'from_messages', 'other', 'from_this_person_to_poi', 'director_fees', 'deferred_income', 'long_term_incentive', 'email_address', 'from_poi_to_this_person']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_all = []\n",
    "for v in data_dict['WHALEY DAVID A']:\n",
    "    features_all.append(v)\n",
    "oldindex = features_all.index('poi')\n",
    "features_all.insert(0, features_all.pop(oldindex))\n",
    "print features_all\n",
    "#print data_dict['SKILLING JEFFREY K']\n",
    "len(features_all)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do EDA and deal with outliers we need to create dataframes. Dataframe is created where index (rows) is names and columns are all the features. In order to summarize the features and see the data we need to rename index to just a colum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rubric questions\n",
    "* total number of data points\n",
    "* allocation across classes (POI/non-POI)\n",
    "* number of features used\n",
    "* are there features with many missing values? etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 Outliers\n",
    "To identify outliers we need to transfer data to dataframe.\n",
    "We identified three clear outliers (TOTAL,  THE TRAVEL AGENCY, LOCKHART EUGENE E ). THE TRAVEL AGENCY and TOTAL are not real persons and should be taken out.  Mr. Lockhart does not have any data to his name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azizmamatov/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import pandas as pd\n",
    "def to_pandas(data_dict):\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    df = df.convert_objects(convert_numeric=True) #converted objects to Numbeic, like POI which was boolean\n",
    "    df = df.transpose() #original data_dict had all the info in rows instead of columns\n",
    "    df.reset_index(level=0, inplace=True) #resets the index column to just a column\n",
    "    columns = list(df.columns)\n",
    "    columns[0] = 'name' #index column is renamed to names\n",
    "    df.columns = columns\n",
    "    return(df)\n",
    "df = to_pandas(data_dict)\n",
    "df.to_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers to rubric questions\n",
    "* All emails adresses are NaN,\n",
    "* 146 people, and 21 features.\n",
    "* 128 non-POI and 18 POI\n",
    "* Following names have this percentage of NaN values: \n",
    "* LOCKHART EUGENE E\t\t95.238095\n",
    "* GRAMM WENDY L\t85.714286\n",
    "* SCRIMSHAW MATTHEW\t85.714286\n",
    "* THE TRAVEL AGENCY IN THE PARK\t85.714286\n",
    "* WHALEY DAVID A\t85.714286\n",
    "* WODRASKA JOHN\t85.714286\n",
    "* WROBEL BRUCE\t85.714286\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poi\n",
      "0.0    128\n",
      "1.0     18\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azizmamatov/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.200000e+01</td>\n",
       "      <td>3.900000e+01</td>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.020000e+02</td>\n",
       "      <td>9.500000e+01</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.600000e+01</td>\n",
       "      <td>9.300000e+01</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>1.100000e+02</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>9.500000e+01</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.250000e+02</td>\n",
       "      <td>1.260000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.374235e+06</td>\n",
       "      <td>1.642674e+06</td>\n",
       "      <td>-1.140475e+06</td>\n",
       "      <td>1.668049e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.987054e+06</td>\n",
       "      <td>1.087289e+05</td>\n",
       "      <td>608.790698</td>\n",
       "      <td>64.895349</td>\n",
       "      <td>41.232558</td>\n",
       "      <td>...</td>\n",
       "      <td>1.470361e+06</td>\n",
       "      <td>9.190650e+05</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>2.321741e+06</td>\n",
       "      <td>1.664106e+05</td>\n",
       "      <td>5.621943e+05</td>\n",
       "      <td>1176.465116</td>\n",
       "      <td>2073.860465</td>\n",
       "      <td>5.081526e+06</td>\n",
       "      <td>6.773957e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.071333e+07</td>\n",
       "      <td>5.161930e+06</td>\n",
       "      <td>4.025406e+06</td>\n",
       "      <td>3.198914e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.106201e+07</td>\n",
       "      <td>5.335348e+05</td>\n",
       "      <td>1841.033949</td>\n",
       "      <td>86.979244</td>\n",
       "      <td>100.073111</td>\n",
       "      <td>...</td>\n",
       "      <td>5.942759e+06</td>\n",
       "      <td>4.589253e+06</td>\n",
       "      <td>0.329899</td>\n",
       "      <td>1.251828e+07</td>\n",
       "      <td>4.201494e+06</td>\n",
       "      <td>2.716369e+06</td>\n",
       "      <td>1178.317641</td>\n",
       "      <td>2582.700981</td>\n",
       "      <td>2.906172e+07</td>\n",
       "      <td>3.895777e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>-1.025000e+05</td>\n",
       "      <td>-2.799289e+07</td>\n",
       "      <td>3.285000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.285000e+03</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.922300e+04</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.604490e+06</td>\n",
       "      <td>-7.576788e+06</td>\n",
       "      <td>4.770000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>-4.409300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.734362e+07</td>\n",
       "      <td>3.208340e+07</td>\n",
       "      <td>-8.330000e+02</td>\n",
       "      <td>1.398517e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.117640e+08</td>\n",
       "      <td>5.235198e+06</td>\n",
       "      <td>14368.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.852193e+07</td>\n",
       "      <td>4.266759e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.303223e+08</td>\n",
       "      <td>1.545629e+07</td>\n",
       "      <td>2.670423e+07</td>\n",
       "      <td>5521.000000</td>\n",
       "      <td>15149.000000</td>\n",
       "      <td>3.098866e+08</td>\n",
       "      <td>4.345095e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              bonus  deferral_payments  deferred_income  director_fees  \\\n",
       "count  8.200000e+01       3.900000e+01     4.900000e+01   1.700000e+01   \n",
       "mean   2.374235e+06       1.642674e+06    -1.140475e+06   1.668049e+05   \n",
       "std    1.071333e+07       5.161930e+06     4.025406e+06   3.198914e+05   \n",
       "min    7.000000e+04      -1.025000e+05    -2.799289e+07   3.285000e+03   \n",
       "25%             NaN                NaN              NaN            NaN   \n",
       "50%             NaN                NaN              NaN            NaN   \n",
       "75%             NaN                NaN              NaN            NaN   \n",
       "max    9.734362e+07       3.208340e+07    -8.330000e+02   1.398517e+06   \n",
       "\n",
       "       email_address  exercised_stock_options      expenses  from_messages  \\\n",
       "count            0.0             1.020000e+02  9.500000e+01      86.000000   \n",
       "mean             NaN             5.987054e+06  1.087289e+05     608.790698   \n",
       "std              NaN             3.106201e+07  5.335348e+05    1841.033949   \n",
       "min              NaN             3.285000e+03  1.480000e+02      12.000000   \n",
       "25%              NaN                      NaN           NaN            NaN   \n",
       "50%              NaN                      NaN           NaN            NaN   \n",
       "75%              NaN                      NaN           NaN            NaN   \n",
       "max              NaN             3.117640e+08  5.235198e+06   14368.000000   \n",
       "\n",
       "       from_poi_to_this_person  from_this_person_to_poi        ...          \\\n",
       "count                86.000000                86.000000        ...           \n",
       "mean                 64.895349                41.232558        ...           \n",
       "std                  86.979244               100.073111        ...           \n",
       "min                   0.000000                 0.000000        ...           \n",
       "25%                        NaN                      NaN        ...           \n",
       "50%                        NaN                      NaN        ...           \n",
       "75%                        NaN                      NaN        ...           \n",
       "max                 528.000000               609.000000        ...           \n",
       "\n",
       "       long_term_incentive         other         poi  restricted_stock  \\\n",
       "count         6.600000e+01  9.300000e+01  146.000000      1.100000e+02   \n",
       "mean          1.470361e+06  9.190650e+05    0.123288      2.321741e+06   \n",
       "std           5.942759e+06  4.589253e+06    0.329899      1.251828e+07   \n",
       "min           6.922300e+04  2.000000e+00    0.000000     -2.604490e+06   \n",
       "25%                    NaN           NaN    0.000000               NaN   \n",
       "50%                    NaN           NaN    0.000000               NaN   \n",
       "75%                    NaN           NaN    0.000000               NaN   \n",
       "max           4.852193e+07  4.266759e+07    1.000000      1.303223e+08   \n",
       "\n",
       "       restricted_stock_deferred        salary  shared_receipt_with_poi  \\\n",
       "count               1.800000e+01  9.500000e+01                86.000000   \n",
       "mean                1.664106e+05  5.621943e+05              1176.465116   \n",
       "std                 4.201494e+06  2.716369e+06              1178.317641   \n",
       "min                -7.576788e+06  4.770000e+02                 2.000000   \n",
       "25%                          NaN           NaN                      NaN   \n",
       "50%                          NaN           NaN                      NaN   \n",
       "75%                          NaN           NaN                      NaN   \n",
       "max                 1.545629e+07  2.670423e+07              5521.000000   \n",
       "\n",
       "        to_messages  total_payments  total_stock_value  \n",
       "count     86.000000    1.250000e+02       1.260000e+02  \n",
       "mean    2073.860465    5.081526e+06       6.773957e+06  \n",
       "std     2582.700981    2.906172e+07       3.895777e+07  \n",
       "min       57.000000    1.480000e+02      -4.409300e+04  \n",
       "25%             NaN             NaN                NaN  \n",
       "50%             NaN             NaN                NaN  \n",
       "75%             NaN             NaN                NaN  \n",
       "max    15149.000000    3.098866e+08       4.345095e+08  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "print df.groupby(['poi']).size() # we can see number of poi\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Total' outlier.\n",
    "Total is just a sum of values and should be taken out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>97343619.0</td>\n",
       "      <td>32083396.0</td>\n",
       "      <td>-27992891.0</td>\n",
       "      <td>1398517.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>311764000.0</td>\n",
       "      <td>5235198.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>48521928.0</td>\n",
       "      <td>42667589.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130322299.0</td>\n",
       "      <td>-7576788.0</td>\n",
       "      <td>26704229.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309886585.0</td>\n",
       "      <td>434509511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>SKILLING JEFFREY K</td>\n",
       "      <td>5600000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19250000.0</td>\n",
       "      <td>29336.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1920000.0</td>\n",
       "      <td>22122.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6843672.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1111258.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>3627.0</td>\n",
       "      <td>8682716.0</td>\n",
       "      <td>26093672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>LAY KENNETH L</td>\n",
       "      <td>7000000.0</td>\n",
       "      <td>202911.0</td>\n",
       "      <td>-300000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34348384.0</td>\n",
       "      <td>99832.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>10359729.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14761694.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1072321.0</td>\n",
       "      <td>2411.0</td>\n",
       "      <td>4273.0</td>\n",
       "      <td>103559793.0</td>\n",
       "      <td>49110078.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>FREVERT MARK A</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>6426990.0</td>\n",
       "      <td>-3367011.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10433518.0</td>\n",
       "      <td>86987.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1617011.0</td>\n",
       "      <td>7427621.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4188667.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1060932.0</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>17252530.0</td>\n",
       "      <td>14622185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>PICKERING MARK R</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28798.0</td>\n",
       "      <td>31653.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>655037.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>1386690.0</td>\n",
       "      <td>28798.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name       bonus  deferral_payments  deferred_income  \\\n",
       "130               TOTAL  97343619.0         32083396.0      -27992891.0   \n",
       "122  SKILLING JEFFREY K   5600000.0                NaN              NaN   \n",
       "79        LAY KENNETH L   7000000.0           202911.0        -300000.0   \n",
       "47       FREVERT MARK A   2000000.0          6426990.0       -3367011.0   \n",
       "105    PICKERING MARK R    300000.0                NaN              NaN   \n",
       "\n",
       "     director_fees  email_address  exercised_stock_options   expenses  \\\n",
       "130      1398517.0            NaN              311764000.0  5235198.0   \n",
       "122            NaN            NaN               19250000.0    29336.0   \n",
       "79             NaN            NaN               34348384.0    99832.0   \n",
       "47             NaN            NaN               10433518.0    86987.0   \n",
       "105            NaN            NaN                  28798.0    31653.0   \n",
       "\n",
       "     from_messages  from_poi_to_this_person        ...          \\\n",
       "130            NaN                      NaN        ...           \n",
       "122          108.0                     88.0        ...           \n",
       "79            36.0                    123.0        ...           \n",
       "47            21.0                    242.0        ...           \n",
       "105           67.0                      7.0        ...           \n",
       "\n",
       "     long_term_incentive       other  poi  restricted_stock  \\\n",
       "130           48521928.0  42667589.0  0.0       130322299.0   \n",
       "122            1920000.0     22122.0  1.0         6843672.0   \n",
       "79             3600000.0  10359729.0  1.0        14761694.0   \n",
       "47             1617011.0   7427621.0  0.0         4188667.0   \n",
       "105                  NaN         NaN  0.0               NaN   \n",
       "\n",
       "     restricted_stock_deferred      salary  shared_receipt_with_poi  \\\n",
       "130                 -7576788.0  26704229.0                      NaN   \n",
       "122                        NaN   1111258.0                   2042.0   \n",
       "79                         NaN   1072321.0                   2411.0   \n",
       "47                         NaN   1060932.0                   2979.0   \n",
       "105                        NaN    655037.0                    728.0   \n",
       "\n",
       "     to_messages  total_payments  total_stock_value  \n",
       "130          NaN     309886585.0        434509511.0  \n",
       "122       3627.0       8682716.0         26093672.0  \n",
       "79        4273.0     103559793.0         49110078.0  \n",
       "47        3275.0      17252530.0         14622185.0  \n",
       "105        898.0       1386690.0            28798.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name'].groupby(df['salary']).max()\n",
    "df.sort_values(by=['salary','name'], ascending=[False, False]).head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New dataframe with columns by names to determine NaN and similar data for our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azizmamatov/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "df['name'].isnull().sum()\n",
    "df_names = pd.DataFrame(data_dict)\n",
    "df_names = df_names.convert_objects(convert_numeric=True)\n",
    "#df_names.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formula to determine NaN values for names\n",
    "Nice summary, where first seven names have too many Nan values (more than 85%). LOCKHART EUGENE E does not have any values - all 20 columns are empty for him and he should be taken out of the list.\n",
    "I took the below code from : https://stackoverflow.com/questions/26266362/how-to-count-the-nan-values-in-the-column-in-panda-data-frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOCKHART EUGENE E</th>\n",
       "      <td>20</td>\n",
       "      <td>95.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRAMM WENDY L</th>\n",
       "      <td>18</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCRIMSHAW MATTHEW</th>\n",
       "      <td>18</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THE TRAVEL AGENCY IN THE PARK</th>\n",
       "      <td>18</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHALEY DAVID A</th>\n",
       "      <td>18</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WODRASKA JOHN</th>\n",
       "      <td>18</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WROBEL BRUCE</th>\n",
       "      <td>18</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHRISTODOULOU DIOMEDES</th>\n",
       "      <td>17</td>\n",
       "      <td>80.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLINE KENNETH W</th>\n",
       "      <td>17</td>\n",
       "      <td>80.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GILLIS JOHN</th>\n",
       "      <td>17</td>\n",
       "      <td>80.952381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Missing Values  % of Total Values\n",
       "LOCKHART EUGENE E                          20          95.238095\n",
       "GRAMM WENDY L                              18          85.714286\n",
       "SCRIMSHAW MATTHEW                          18          85.714286\n",
       "THE TRAVEL AGENCY IN THE PARK              18          85.714286\n",
       "WHALEY DAVID A                             18          85.714286\n",
       "WODRASKA JOHN                              18          85.714286\n",
       "WROBEL BRUCE                               18          85.714286\n",
       "CHRISTODOULOU DIOMEDES                     17          80.952381\n",
       "CLINE KENNETH W                            17          80.952381\n",
       "GILLIS JOHN                                17          80.952381"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names.isnull().sum()\n",
    "def missing_values_table(df): \n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum()/len(df)\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        return mis_val_table_ren_columns \n",
    "names_dataframe = missing_values_table(df_names) \n",
    "#sorting the names descending and showing first 10 names only\n",
    "names_dataframe.sort_values(by=['Missing Values','% of Total Values'], ascending=[False, False]).head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Deleted outliers from data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del data_dict['TOTAL']\n",
    "del data_dict['THE TRAVEL AGENCY IN THE PARK']\n",
    "del data_dict['LOCKHART EUGENE E']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 New features\n",
    "* 'Total stock value' = 'exercised_stock_options' + 'restricted_stock' + 'restricted_stock_deferred'\n",
    " \n",
    "* 'Total payments'= 'salary' + 'deferral_payments' + 'bonus'+ 'expenses' + 'loan_advances'+ 'director_fees' 'deferred_income' + 'long_term_incentive'\n",
    "Will divide features by financials, non-financial and label.\n",
    "\n",
    "#### Majority of financial features have wide ranging amounts and as such should can be loged - will create new features which are logs of the existing ones.\n",
    "\n",
    "#### Non-financial features should be added with ratio based ones, like percentage of poi related message to total messages.\n",
    "* 'poi_ratio_from' = 'from_this_person_to_poi' / 'from_messages'\n",
    "* 'poi_ratio_to' = 'from_poi_to_this_person' / 'to_messages'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8098092096 0.0470879801735 13.8755015673\n",
      "12.4953858869 NaN 15.5443911059\n",
      "12.0490737467 NaN 12.2630435418\n",
      "NaN 0.0130890052356 NaN\n",
      "12.4020217573 0.0306220095694 12.5730810152\n",
      "12.4953521913 NaN 13.3511263104\n",
      "NaN 0.0 14.4297373591\n",
      "12.822468363 0.0246284501062 15.2264416765\n",
      "NaN 0.0187234042553 14.9571376352\n",
      "12.19142083 0.0492730210016 14.3680320983\n",
      "11.7808435094 0.078125 14.9469849249\n",
      "12.5727588096 0.108108108108 13.9381360721\n",
      "12.4233832181 0.010101010101 14.5160478642\n",
      "12.4587206287 0.013978088402 14.2505726553\n",
      "NaN 0.0 13.7814593399\n",
      "NaN NaN NaN\n",
      "12.5725959349 0.136518771331 14.2145175238\n",
      "12.4358104072 0.0882352941176 14.9793080336\n",
      "12.5726513846 0.0968992248062 13.2198058278\n",
      "11.0626303409 NaN 13.5438789843\n",
      "NaN NaN 11.3783649716\n",
      "12.7857459302 0.0253353204173 14.4026192153\n",
      "12.5115037675 0.0302227573751 15.0599939163\n",
      "NaN NaN NaN\n",
      "NaN NaN 11.5376180776\n",
      "12.625144757 0.0291834833903 14.9269410085\n",
      "NaN NaN 12.1525822023\n",
      "12.1437822621 0.0104438642298 13.335618196\n",
      "NaN NaN 12.3399739697\n",
      "12.2719774204 0.014312383323 14.5321755149\n",
      "12.4260150787 0.0263554216867 13.9100022211\n",
      "NaN NaN NaN\n",
      "12.3516005415 0.0196855775803 13.7840900638\n",
      "NaN 0.00698080279232 6.16331480403\n",
      "12.1131072147 NaN 14.8059153191\n",
      "NaN NaN 4.99721227376\n",
      "12.2633410533 0.030303030303 14.5487415406\n",
      "NaN NaN NaN\n",
      "NaN 0.0105042016807 NaN\n",
      "NaN 0.031746031746 8.98230989909\n",
      "NaN 0.0174459176553 NaN\n",
      "12.3207620118 NaN 14.7910553729\n",
      "12.5199559481 0.0237420269313 14.7954248926\n",
      "12.7346045832 0.072737291638 16.1597899369\n",
      "12.2857245076 NaN 12.3391776973\n",
      "12.2572409321 NaN 14.0016440069\n",
      "NaN NaN 12.2693807225\n",
      "NaN 0.0 NaN\n",
      "12.5167874171 NaN 14.5795695011\n",
      "6.16751649089 0.0689045936396 13.727986686\n",
      "NaN NaN 11.2579299842\n",
      "12.5027491466 0.00488481087861 13.8714635789\n",
      "12.9686992459 0.00878569187324 15.2823216682\n",
      "12.2636054337 0.0577777777778 14.5105983543\n",
      "NaN NaN 11.3793026396\n",
      "12.236218654 0.16106442577 14.0050137649\n",
      "12.0682233728 NaN 13.4658055532\n",
      "13.1428794756 0.0309021432132 15.3582901574\n",
      "12.8077567367 0.0276359267047 14.5580972157\n",
      "NaN 0.0 NaN\n",
      "12.8080991082 0.0213385063046 15.3732296118\n",
      "12.0001487316 NaN 13.8148663505\n",
      "NaN NaN NaN\n",
      "12.3735216522 NaN 13.6829946496\n",
      "NaN NaN 7.67368812927\n",
      "13.8853360161 0.0287853966768 18.455659714\n",
      "12.4742507461 NaN 14.0557723525\n",
      "12.7040500837 0.0168918918919 14.0943211449\n",
      "NaN 0.0604026845638 NaN\n",
      "12.127565009 NaN 13.6022628806\n",
      "12.1652923168 NaN 13.7107998311\n",
      "12.4814784217 0.0298165137615 14.092204734\n",
      "12.4786271207 NaN 14.0759198358\n",
      "NaN NaN NaN\n",
      "NaN NaN NaN\n",
      "12.8323452452 0.0448989773011 15.1659354841\n",
      "12.5375359297 0.0753498385361 14.7974350859\n",
      "NaN NaN NaN\n",
      "12.2018487374 0.00106837606838 14.1625390239\n",
      "NaN 0.0 NaN\n",
      "11.4808154111 0.122082585278 11.6220399258\n",
      "11.299954992 NaN 13.6648457953\n",
      "12.2737266211 0.0285320986109 15.5205549699\n",
      "12.2581526304 0.117256637168 14.5542346505\n",
      "12.3108514921 0.0 13.7227953084\n",
      "12.9961151126 NaN 14.7009638665\n",
      "NaN 0.0 12.1104149053\n",
      "12.3891813924 0.076597382602 14.3097780494\n",
      "12.9495231306 0.046408839779 13.1324127133\n",
      "12.5248935819 0.00889950075971 13.8987674791\n",
      "NaN NaN NaN\n",
      "12.658065042 0.0 13.9120863002\n",
      "11.461010925 NaN 12.4283638337\n",
      "NaN NaN 10.2378862122\n",
      "12.3863170465 NaN 13.9217489881\n",
      "13.9210032649 0.0242624758754 15.9768449409\n",
      "NaN NaN 7.15383380158\n",
      "NaN 0.0636215334421 NaN\n",
      "NaN NaN 13.2434263615\n",
      "8.79709507655 NaN 13.9523621825\n",
      "13.3924470016 0.00779510022272 14.1424301704\n",
      "NaN NaN 12.799664649\n",
      "NaN NaN 13.5598451063\n",
      "12.9100064408 0.0109769484083 14.3737093424\n",
      "17.1003325003 NaN 19.5517169337\n",
      "NaN 0.0 NaN\n",
      "12.4684215253 0.055 13.8493272727\n",
      "12.6683685212 NaN 14.4752865634\n",
      "NaN NaN NaN\n",
      "12.2158001793 0.0161957270848 15.316124631\n",
      "12.4217725616 0.00765306122449 14.2707247354\n",
      "NaN NaN 11.3355914497\n",
      "NaN NaN 11.3503124134\n",
      "NaN 0.00874831763122 10.8054359227\n",
      "NaN NaN 12.1143191333\n",
      "NaN 0.0486787204451 NaN\n",
      "11.2437248861 NaN 12.8853110459\n",
      "12.4791029024 NaN 14.6776200398\n",
      "NaN 0.0 16.5535265982\n",
      "12.4753705093 0.0929487179487 13.0764388035\n",
      "12.4212525712 0.0 13.8687071899\n",
      "NaN NaN 10.9168505472\n",
      "12.3427166888 0.00501824817518 13.6074945069\n",
      "12.3542598649 0.0478468899522 14.2643345998\n",
      "12.3059315551 0.0568181818182 12.6758918828\n",
      "11.9728976976 NaN 12.7946922967\n",
      "NaN NaN 11.4196362417\n",
      "12.4296161169 0.118584758942 14.1594292862\n",
      "13.1069959003 0.0293443374599 13.2194556048\n",
      "13.8746583251 0.073893129771 16.6634693574\n",
      "12.475637844 NaN 14.9544272672\n",
      "12.3870224285 NaN 13.6264012162\n",
      "NaN 0.0132125330313 NaN\n",
      "NaN NaN 10.8315289738\n",
      "12.6267153227 0.0239316239316 15.11742825\n",
      "12.6441533677 0.0223251895535 14.2776212447\n",
      "NaN NaN 8.22951111896\n",
      "11.3536248805 0.0564516129032 14.4984033414\n",
      "12.4185111012 0.0217391304348 12.8977011735\n",
      "12.764221644 0.00525624178712 15.9445771533\n",
      "12.7085011116 0.0442804428044 14.6723493302\n",
      "NaN NaN 11.689329548\n",
      "12.9364891172 0.0306553911205 14.440784597\n",
      "12.4882923262 0.0 13.9041283939\n",
      "12.5375359297 0.217341040462 13.6828473598\n",
      "12.5244354634 0.0595647193585 14.0563242684\n"
     ]
    }
   ],
   "source": [
    "#divide features by labels and financial and non-financial\n",
    "\n",
    "import pickle\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict_log = pickle.load(data_file)\n",
    "\n",
    "financial_features = ['salary', 'deferral_payments', 'total_payments', 'exercised_stock_options', 'bonus', \n",
    "                      'restricted_stock', 'restricted_stock_deferred', 'total_stock_value', 'expenses',\n",
    "                      'loan_advances','other', 'director_fees', 'deferred_income', 'long_term_incentive']\n",
    "non_financials_features = ['to_messages', 'shared_receipt_with_poi', 'from_messages', \n",
    "                           'from_this_person_to_poi', 'from_poi_to_this_person']\n",
    "poi_label = ['poi']\n",
    "features_new = [\"poi_ratio_from\", 'poi_ratio_to',\"total_payments_log\", \"salary_log\",\"bonus_log\",\n",
    "                \"total_stock_value_log\", \"exercised_stock_options_log\"]\n",
    "\n",
    "NANvalue = 'NaN'\n",
    "for key in data_dict_log:\n",
    "#creating new financial features            \n",
    "    for feat in financial_features:\n",
    "        try:\n",
    "            data_dict_log[key][feat + '_log'] = math.log(data_dict_log[key][feat])\n",
    "        except:\n",
    "            data_dict_log[key][feat + '_log'] = NANvalue   \n",
    "            \n",
    "#creating new non_financial features   \n",
    "    try: \n",
    "        data_dict_log[key]['poi_ratio_from'] = \\\n",
    "        1. * data_dict_log[key]['from_this_person_to_poi'] / data_dict_log[key]['from_messages']\n",
    "        data_dict_log[key]['poi_ratio_to'] = \\\n",
    "        1. * data_dict_log[key]['from_poi_to_this_person'] / data_dict_log[key]['to_messages'] * 1.\n",
    "    except:\n",
    "        data_dict_log[key]['poi_ratio_from'] = NANvalue\n",
    "        data_dict_log[key]['poi_ratio_to'] = NANvalue\n",
    "            \n",
    "            \n",
    "for k, v in data_dict_log.iteritems():\n",
    "    print data_dict_log[k]['salary_log'], \\\n",
    "data_dict_log[k]['poi_ratio_to'], data_dict_log[k]['total_payments_log'] \n",
    "\n",
    "features_list = poi_label + financial_features + non_financials_features + features_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating featureFormat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_dataset = data_dict_log\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True) \n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling features\n",
    "Will scale all the features via min-max algorithm. Some of the algorithms like logistics regression perform the best with scaled features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def scale_features(features):\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "#    return features\n",
    "#scale_features(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(features, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation - not used in final code, but is shown for illustration purposes\n",
    "Need to optimize test and train selection by cross validation and selecting KFold for split and validate algorithm.\n",
    "We need to make sure that we aren't overfitting the data. We will choose different subsets of training and testing data to find out best fit. The best scores are acceptable and the average is acceptable as well, even though it can be improved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "kf=KFold(len(labels),3)\n",
    "for train_indices, test_indices in kf:\n",
    "    #make training and testing sets\n",
    "    features_train= [features[ii] for ii in train_indices]\n",
    "    features_test= [features[ii] for ii in test_indices]\n",
    "    labels_train=[labels[ii] for ii in train_indices]\n",
    "    labels_test=[labels[ii] for ii in test_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "There are various algorithms that we studies including the list below, and I decided to use Decision tree classifier,  Logistic Regression and Gradient Boosting.\n",
    "\n",
    "#### Need to select at least two algorithms, compare their performance and tune the parameters for two algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree classifier\n",
    "We have some manual tuning to determine which parameters to add to each algorithm and adding/removing features. \n",
    "\n",
    "Parameter tuning is important because it optimizes an algorithm's performance on the data set. To measure the algorithm's performance, the data shoulld be validated and evaluated for different combinations of selected parameters. Algorithms are usually general in nature and are not  tuned to particular data set. Therefore, we should iteratively tune the algorithm until a satisfactory outcome is obtained.\n",
    "##### As we can see below the maximum results are under 'min_samples_split' parameter of 2. Parameter 3 also brings acceptable results while larger parameters do not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before tuning, decision tree = 0.758620689655\n",
      "precision before tuning, decision tree =  0.333333333333\n",
      "recall = before tuning, decision tree =  0.75\n",
      "[0.7931034482758621, 0.375, 0.75, 0.75862068965517238, 0.33333333333333331, 0.75, 0.75862068965517238, 0.33333333333333331, 0.75, 0.86206896551724133, 0.0, 0.0, 0.86206896551724133, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azizmamatov/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Please name your classifier clf for easy export below.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train,labels_train)\n",
    "#score = clf.score(features_test,labels_test)\n",
    "pred= clf.predict(features_test)\n",
    "acc=accuracy_score(labels_test, pred)\n",
    "print 'Accuracy before tuning, decision tree =', acc\n",
    "print 'precision before tuning, decision tree = ', precision_score(labels_test,pred)\n",
    "print 'recall = before tuning, decision tree = ', recall_score(labels_test,pred)\n",
    "\n",
    "split = [2,3,5,100,10000]\n",
    "new_scores = []\n",
    "for i in split:\n",
    "    clf = DecisionTreeClassifier(min_samples_split=i)\n",
    "    clf = clf.fit(features_train,labels_train)\n",
    "    pred= clf.predict(features_test)\n",
    "    acc=accuracy_score(labels_test, pred)\n",
    "    new_scores.append(acc)\n",
    "    precision = precision_score(labels_test,pred)\n",
    "    new_scores.append(precision)\n",
    "    recall = recall_score(labels_test,pred)\n",
    "    new_scores.append(recall)\n",
    "\n",
    "print new_scores    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression\n",
    "Maximum scores are under 'C' parameter value of 10 and 10000 in our list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before tuning, logistic regression = 0.862068965517\n",
      "recall before tuning, logistic regression =  0.0\n",
      "precision before tuning, logistic regression =  0.0\n",
      "[0.86206896551724133, 0.0, 0.0, 0.86206896551724133, 0.0, 0.0, 0.86206896551724133, 0.5, 0.25, 0.7931034482758621, 0.25, 0.25]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "acc=accuracy_score(labels_test, pred)\n",
    "print 'Accuracy before tuning, logistic regression =', acc #clf.score(features_train, labels_train)\n",
    "print 'recall before tuning, logistic regression = ', recall_score(labels_test, pred)\n",
    "print 'precision before tuning, logistic regression = ', precision_score(labels_test, pred)\n",
    "\n",
    "C = [5,10,100,10000]\n",
    "new_scores = []\n",
    "for i in C:\n",
    "    clf = LogisticRegression(C=i)\n",
    "    clf = clf.fit(features_train,labels_train)\n",
    "    pred= clf.predict(features_test)\n",
    "    acc=accuracy_score(labels_test, pred)\n",
    "    new_scores.append(acc)\n",
    "    precision = precision_score(labels_test,pred)\n",
    "    new_scores.append(precision)\n",
    "    recall = recall_score(labels_test,pred)\n",
    "    new_scores.append(recall)\n",
    "\n",
    "print new_scores    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Gradient Boosting\n",
    "This algorithm is one of the ensemble methods which is combining the predictions of several base estimators built with a given learning algorithm in order to improve generalizability / robustness over a single estimator.\n",
    "The module sklearn.ensemble provides methods for both classification and regression via gradient boosted regression trees.\n",
    "Maximum scores are under 'max_depth' parameter value of 10 in our list and they stay the same once they increase.\n",
    "##### This algorith has the best score, recall and precision ratios and we are going to be validating and evaluating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before tuning, GradientBoosting  = 0.896551724138\n",
      "recall before tuning,  = GradientBoosting 0.5\n",
      "precision before tuning, = GradientBoosting 0.666666666667\n",
      "[0.89655172413793105, 0.66666666666666663, 0.5, 0.7931034482758621, 0.375, 0.75, 0.7931034482758621, 0.375, 0.75, 0.7931034482758621, 0.375, 0.75, 0.7931034482758621, 0.375, 0.75]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "acc=accuracy_score(labels_test, pred)\n",
    "print 'Accuracy before tuning, GradientBoosting  =', acc #clf.score(features_train, labels_train)\n",
    "print 'recall before tuning,  = GradientBoosting', recall_score(labels_test, pred)\n",
    "print 'precision before tuning, = GradientBoosting', precision_score(labels_test, pred)\n",
    "\n",
    "maxdepth = [2, 5,10,100,10000]\n",
    "new_scores = []\n",
    "for i in maxdepth:\n",
    "    clf = GradientBoostingClassifier(max_depth=i)\n",
    "    clf = clf.fit(features_train,labels_train)\n",
    "    pred= clf.predict(features_test)\n",
    "    acc=accuracy_score(labels_test, pred)\n",
    "    new_scores.append(acc)\n",
    "    precision = precision_score(labels_test,pred)\n",
    "    new_scores.append(precision)\n",
    "    recall = recall_score(labels_test,pred)\n",
    "    new_scores.append(recall)\n",
    "print new_scores    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(max_depth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "The above results came from using all our features. That seems fine here, but what about if the data set was much larger, or had a lot more features - the linear algorithms like Decision Tree or Logistic regression need to have an optimal number of features. Ensemble algorithm deals with this problem. \n",
    "Using too many features can also result in overfitting for linear algorithms. We will try the best features selection for Logistic regression algorithm.\n",
    "Best five feature below return a not very good score and not adequate recall and precision rates. So we need to work more with the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall  0.0\n",
      "precision 0.0\n",
      "BestK score:  0.827586206897\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=10)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# let's see what we can do with the best five features (k=5)\n",
    "best_features = SelectKBest(k=10).fit(features_train, labels_train)\n",
    "\n",
    "features_train_1 = best_features.transform(features_train)\n",
    "features_test_1 = best_features.transform(features_test)\n",
    "\n",
    "clf.fit(features_train_1,labels_train)\n",
    "pred = clf.predict(features_test_1)\n",
    "score = accuracy_score(labels_test, pred)\n",
    "print 'recall ', recall_score(labels_test, pred)\n",
    "print 'precision', precision_score(labels_test, pred)\n",
    "\n",
    "print \"BestK score: \", score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to see if by applying SelectKBest to all features gradually, how the score will change. The below shows inconsistent scores and we need to find another method of feature selection. It seems like some scores are really good while others plainly do not help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html Use this for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.862068965517\n",
      "2 0.827586206897\n",
      "3 0.827586206897\n",
      "4 0.827586206897\n",
      "5 0.827586206897\n",
      "6 0.827586206897\n",
      "7 0.827586206897\n",
      "8 0.827586206897\n",
      "9 0.827586206897\n",
      "10 0.827586206897\n",
      "11 0.827586206897\n",
      "12 0.827586206897\n",
      "13 0.827586206897\n",
      "14 0.827586206897\n",
      "15 0.827586206897\n",
      "16 0.827586206897\n",
      "17 0.827586206897\n",
      "18 0.827586206897\n",
      "19 0.862068965517\n",
      "20 0.862068965517\n",
      "21 0.862068965517\n",
      "22 0.862068965517\n",
      "23 0.862068965517\n",
      "24 0.862068965517\n",
      "25 0.862068965517\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 26):\n",
    "    best_features = SelectKBest(k=i).fit(features_train, labels_train)\n",
    "    features_train_1 = best_features.transform(features_train)\n",
    "    features_test_1 = best_features.transform(features_test)\n",
    "\n",
    "    clf.fit(features_train_1, labels_train)\n",
    "    pred = clf.predict(features_test_1)\n",
    "    score = accuracy_score(labels_test, pred)\n",
    "    print i, score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importances with forests of trees¶\n",
    "We will build a graph to see which features are important for LogisticRegression and as we can see, majority of features are importants with decreasing importance over each feature. The most important features are payment related ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Feature ranking:\n",
      "1. feature salary (0.073581)\n",
      "2. feature deferral_payments (0.067475)\n",
      "3. feature total_payments (0.065931)\n",
      "4. feature exercised_stock_options (0.063135)\n",
      "5. feature bonus (0.059104)\n",
      "6. feature restricted_stock (0.056222)\n",
      "7. feature restricted_stock_deferred (0.054524)\n",
      "8. feature total_stock_value (0.052723)\n",
      "9. feature expenses (0.043110)\n",
      "10. feature loan_advances (0.041496)\n",
      "11. feature other (0.040267)\n",
      "12. feature director_fees (0.039858)\n",
      "13. feature deferred_income (0.038763)\n",
      "14. feature long_term_incentive (0.035780)\n",
      "15. feature to_messages (0.035748)\n",
      "16. feature shared_receipt_with_poi (0.035088)\n",
      "17. feature from_messages (0.034707)\n",
      "18. feature from_this_person_to_poi (0.033836)\n",
      "19. feature from_poi_to_this_person (0.032490)\n",
      "20. feature poi_ratio_from (0.025687)\n",
      "21. feature poi_ratio_to (0.023768)\n",
      "22. feature total_payments_log (0.022117)\n",
      "23. feature salary_log (0.011985)\n",
      "24. feature bonus_log (0.005526)\n",
      "25. feature total_stock_value_log (0.005500)\n",
      "26. feature exercised_stock_options_log (0.001582)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAFyCAYAAABC/SgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAWhYxbAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11429d610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(features_train, labels_train)  # your feature and labels\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "\n",
    "# Build a classification task using 3 informative features\n",
    "X, y = features_train, labels_train\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, features_list[1:][f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch final algorithm with final parameters can be seen below\n",
    "N-estimators = 10, Max_depth = 1, All features are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=1,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=10, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "0.862068965517\n",
      "[mean: 0.87931, std: 0.03421, params: {'n_estimators': 10, 'max_depth': 1}, mean: 0.83621, std: 0.06740, params: {'n_estimators': 100, 'max_depth': 1}, mean: 0.79310, std: 0.05349, params: {'n_estimators': 1000, 'max_depth': 1}, mean: 0.85345, std: 0.04773, params: {'n_estimators': 10, 'max_depth': 2}, mean: 0.81034, std: 0.06369, params: {'n_estimators': 100, 'max_depth': 2}, mean: 0.78448, std: 0.08050, params: {'n_estimators': 1000, 'max_depth': 2}, mean: 0.81897, std: 0.04036, params: {'n_estimators': 10, 'max_depth': 5}, mean: 0.81897, std: 0.05729, params: {'n_estimators': 100, 'max_depth': 5}, mean: 0.81897, std: 0.05729, params: {'n_estimators': 1000, 'max_depth': 5}]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# applying GridSearch on GradientBoostingClassifier only\n",
    "\n",
    "param_grid = {'n_estimators': [10, 100, 1000],'max_depth': [1, 2, 5]}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), cv=10, n_jobs=-1, param_grid=param_grid)\n",
    "grid_search.fit(features_train, labels_train)\n",
    "clf = grid_search.best_estimator_\n",
    "\n",
    "print clf\n",
    "print grid_search.best_estimator_.score(features_test, labels_test)\n",
    "print grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gridseach with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('reduce_dim', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('clf', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=5,\n",
      "              max_featur...=100, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False))])\n",
      "0.862068965517\n",
      "[mean: 0.85345, std: 0.06526, params: {'clf__max_depth': 5, 'reduce_dim__n_components': 2}, mean: 0.85345, std: 0.07689, params: {'clf__max_depth': 5, 'reduce_dim__n_components': 3}, mean: 0.85345, std: 0.06526, params: {'clf__max_depth': 6, 'reduce_dim__n_components': 2}, mean: 0.85345, std: 0.09227, params: {'clf__max_depth': 6, 'reduce_dim__n_components': 3}]\n"
     ]
    }
   ],
   "source": [
    "# applying grid search on GradientBoostingClassifier but with pipeline which inludes PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "estimators = [('reduce_dim', PCA()), ('clf', GradientBoostingClassifier())]\n",
    "pipe = Pipeline(estimators)\n",
    " \n",
    "\n",
    "#param_grid = dict(selectkbest__k = range(20,25))\n",
    "\n",
    "param_grid = {'reduce_dim__n_components': [2, 3],\n",
    "               'clf__max_depth': [5,6]\n",
    "          }\n",
    "\n",
    "grid_search = GridSearchCV(pipe, cv=10, n_jobs=-1, param_grid = param_grid)\n",
    "grid_search.fit(features_train, labels_train)\n",
    "clf = grid_search.best_estimator_\n",
    "\n",
    "print clf\n",
    "print grid_search.best_estimator_.score(features_test, labels_test)\n",
    "print grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclf_final = GradientBoostingClassifier(criterion='friedman_mse', init=None,\\n              learning_rate=0.1, loss='deviance', max_depth=1,\\n              max_features=None, max_leaf_nodes=None,\\n              min_impurity_split=1e-07, min_samples_leaf=1,\\n              min_samples_split=2, min_weight_fraction_leaf=0.0,\\n              n_estimators=10, presort='auto', random_state=None,\\n              subsample=1.0, verbose=0, warm_start=False)\\nclf = clf_final.fit(features_train, labels_train)\\npred = clf_final.predict(features_test)\\nacc=accuracy_score(labels_test, pred)\\nprint 'Accuracy before tuning, GradientBoosting  =', acc\\nprint 'precision = ', precision_score(labels_test,pred)\\nprint 'recall = ', recall_score(labels_test,pred)\\n\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "clf_final = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "              learning_rate=0.1, loss='deviance', max_depth=1,\n",
    "              max_features=None, max_leaf_nodes=None,\n",
    "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "              n_estimators=10, presort='auto', random_state=None,\n",
    "              subsample=1.0, verbose=0, warm_start=False)\n",
    "clf = clf_final.fit(features_train, labels_train)\n",
    "pred = clf_final.predict(features_test)\n",
    "acc=accuracy_score(labels_test, pred)\n",
    "print 'Accuracy before tuning, GradientBoosting  =', acc\n",
    "print 'precision = ', precision_score(labels_test,pred)\n",
    "print 'recall = ', recall_score(labels_test,pred)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "* http://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting\n",
    "* http://scikit-learn.org/stable/modules/pipeline.html\n",
    "* http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "* https://stackoverflow.com/questions/26266362/how-to-count-the-nan-values-in-the-column-in-panda-data-frame\n",
    "* http://chris-said.io/2016/02/13/how-to-make-polished-jupyter-presentations-with-optional-code-visibility/\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#999; background:#fff;\">\n",
    "Created with Jupyter, delivered by Fastly, rendered by Rackspace.\n",
    "</footer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
